# Finetuning LLM models

This project demonstrates end-to-end fine-tuning of Large Language Models (LLMs) using different approaches and frameworks. The repository contains two main implementations:

# Google Gemma Fine-tuning

• Fine-tunes Google's open-source Gemma model using LoRA technique in Keras
• Implements efficient parameter-efficient fine-tuning reducing trainable parameters from billions to millions
• Includes complete setup from API configuration to model deployment
• Demonstrates inference capabilities before and after fine-tuning

# Lamini AI Cloud Fine-tuning

• Provides a simplified approach to LLM fine-tuning using Lamini's cloud platform
• Supports various models including Llama 3
• Features easy data preparation and model evaluation
• Includes playground for testing and public model sharing capabilities


The project aims to make LLM fine-tuning accessible by providing practical implementations with detailed explanations and comparisons of different approaches. Perfect for developers looking to customize language models for specific use cases.
